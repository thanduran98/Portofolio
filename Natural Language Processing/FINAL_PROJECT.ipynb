{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL :: NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4glEKcaHY26"
      },
      "source": [
        "**Gabriela Nathania Harywanto** <br>\n",
        "**2201797494**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_4LPO97kCB2"
      },
      "source": [
        "**Import Library yang Digunakan**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfOvdhtwXytO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NGJ6n-5kLYU"
      },
      "source": [
        "**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peCNcE5TX4jo",
        "outputId": "0b848470-27a9-47a4-fc8b-f6f49a2db842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "review = [\n",
        "        'This was a great movie with a good cast, all of them hitting on all cylinders',\n",
        "        'Even if you\\'re a huge Sandler fan, please don\\'t bother with this extremely disappointing comedy!',\n",
        "        'A movie of outstanding brilliance and a poignant and unusual love story',\n",
        "        'I had the misfortune to watch this rubbish on Sky Cinema Max in a cold winter night',\n",
        "        'I am at a distinct disadvantage here. I have not seen the first two movies in this series',\n",
        "        'This program is a lot of fun and the title song is so catchy I can\\'t get it out of my head'\n",
        "]\n",
        "label =[1,0,1,0,0,1]\n",
        "data = pd.DataFrame(list(zip(review, label)),columns =['review', 'label'])\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Even if you're a huge Sandler fan, please don'...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  This was a great movie with a good cast, all o...      1\n",
              "1  Even if you're a huge Sandler fan, please don'...      0\n",
              "2  A movie of outstanding brilliance and a poigna...      1\n",
              "3  I had the misfortune to watch this rubbish on ...      0\n",
              "4  I am at a distinct disadvantage here. I have n...      0\n",
              "5  This program is a lot of fun and the title son...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1CUsv-ifP00"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCU9SAA1lVsp"
      },
      "source": [
        "Preprocessing yang akan dilakukan meliputi:\n",
        "\n",
        "1.   **Expanding Abbreviations**<br>\n",
        "Pada data review terdapat beberapa singkatan seperti \"**you're**\", \"**don't**\" dan \"**can't**\" yang akan mengganggu ketika dilakukan pemisahan kata, sebab sebenarnya kata tersebut merupakan gabungan dari 2 kata. Oleh karena itu, dilakukan *Expanding Abbreviations* sehingga di peroleh bentuk yang lebih general."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcYHjb4Pu1Ux"
      },
      "source": [
        "### Expanding Abbreviations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nS3UhOZu4AC",
        "outputId": "0649a964-0957-4e3a-9086-b4a0abf1d74e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "# mengubah kata you're, don't dan can't menjadi 'you are', 'do not', dan 'can not'\n",
        "tmp = [\n",
        "        'This was a great movie with a good cast, all of them hitting on all cylinders',\n",
        "        'Even if you are a huge Sandler fan, please do not bother with this extremely disappointing comedy!',\n",
        "        'A movie of outstanding brilliance and a poignant and unusual love story',\n",
        "        'I had the misfortune to watch this rubbish on Sky Cinema Max in a cold winter night',\n",
        "        'I am at a distinct disadvantage here. I have not seen the first two movies in this series',\n",
        "        'This program is a lot of fun and the title song is so catchy I can not get it out of my head'\n",
        "]\n",
        "data['Expanding_Abbreviations'] = tmp\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>Expanding_Abbreviations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>1</td>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Even if you're a huge Sandler fan, please don'...</td>\n",
              "      <td>0</td>\n",
              "      <td>Even if you are a huge Sandler fan, please do ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>1</td>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>0</td>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>1</td>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                            Expanding_Abbreviations\n",
              "0  This was a great movie with a good cast, all o...  ...  This was a great movie with a good cast, all o...\n",
              "1  Even if you're a huge Sandler fan, please don'...  ...  Even if you are a huge Sandler fan, please do ...\n",
              "2  A movie of outstanding brilliance and a poigna...  ...  A movie of outstanding brilliance and a poigna...\n",
              "3  I had the misfortune to watch this rubbish on ...  ...  I had the misfortune to watch this rubbish on ...\n",
              "4  I am at a distinct disadvantage here. I have n...  ...  I am at a distinct disadvantage here. I have n...\n",
              "5  This program is a lot of fun and the title son...  ...  This program is a lot of fun and the title son...\n",
              "\n",
              "[6 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xedz82RJeWS"
      },
      "source": [
        "2. **Removing Punctuations, Accent Marks and Other Diacritics**<br>\n",
        "Tanda baca dan segala aksen akan dibuang sehingga menghasilkan data review yang bersih. Segala simbol/tanda ini dibuang karena tidak akan memiliki makna yang berarti saat digunkan, malahan akan mengganggu/menyulitkan proses yang ada. Mengingat bahasa yang digunakan adalah bahasa Inggris, tidak terlalu bergantung padan simbol/tanda pada suatu kata yang mempengarhui artinya. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjE40fDsvX5x"
      },
      "source": [
        "### Removing Punctuations, Accent Marks and Other Diacritics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYsruRXkvbIu",
        "outputId": "5e3fe8d0-52b6-4efc-c356-640a82d0d2c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "# membuang tanda , ! .\n",
        "tmp = [\n",
        "        'This was a great movie with a good cast all of them hitting on all cylinders',\n",
        "        'Even if you are a huge Sandler fan please do not bother with this extremely disappointing comedy',\n",
        "        'A movie of outstanding brilliance and a poignant and unusual love story',\n",
        "        'I had the misfortune to watch this rubbish on Sky Cinema Max in a cold winter night',\n",
        "        'I am at a distinct disadvantage here I have not seen the first two movies in this series',\n",
        "        'This program is a lot of fun and the title song is so catchy I can not get it out of my head'\n",
        "]\n",
        "\n",
        "data['Removing_Symbol'] = tmp\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>Expanding_Abbreviations</th>\n",
              "      <th>Removing_Symbol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>1</td>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>This was a great movie with a good cast all of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Even if you're a huge Sandler fan, please don'...</td>\n",
              "      <td>0</td>\n",
              "      <td>Even if you are a huge Sandler fan, please do ...</td>\n",
              "      <td>Even if you are a huge Sandler fan please do n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>1</td>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>0</td>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>I am at a distinct disadvantage here I have no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>1</td>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                    Removing_Symbol\n",
              "0  This was a great movie with a good cast, all o...  ...  This was a great movie with a good cast all of...\n",
              "1  Even if you're a huge Sandler fan, please don'...  ...  Even if you are a huge Sandler fan please do n...\n",
              "2  A movie of outstanding brilliance and a poigna...  ...  A movie of outstanding brilliance and a poigna...\n",
              "3  I had the misfortune to watch this rubbish on ...  ...  I had the misfortune to watch this rubbish on ...\n",
              "4  I am at a distinct disadvantage here. I have n...  ...  I am at a distinct disadvantage here I have no...\n",
              "5  This program is a lot of fun and the title son...  ...  This program is a lot of fun and the title son...\n",
              "\n",
              "[6 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZLAhvM4JhoE"
      },
      "source": [
        "3.   **Word Tokenization**<br>\n",
        "Sebagian besar review terdiri dari 1 kalimat, kecuali review ke 5. Oleh karena itu tokenization yang dilikakukan langsung pada tingkat kata. Pemisahan akan dilakukan berdasarkan adanya pemisah antarkata yakni spasi. Untuk proses word embedding sendiri dipelrukan data yang telah terpisahkan per kata. Oleh karena itu, proses ini dilakukan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzqCHwMtv3TU"
      },
      "source": [
        "### Word Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJeUZxZqxkkU",
        "outputId": "204c49a5-b97c-4594-9b8a-27f1929a2295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "# memenggal setiap kata, berdasarkan pemisah ' ' (spasi)\n",
        "tmp = [\n",
        "        ['This', 'was', 'a', 'great', 'movie', 'with', 'a', 'good', 'cast', 'all', 'of', 'them', 'hitting', 'on', 'all', 'cylinders'],\n",
        "        ['Even', 'if', 'you', 'are', 'a', 'huge', 'Sandler', 'fan', 'please', 'do', 'not', 'bother', 'with', 'this', 'extremely', 'disappointing', 'comedy'],\n",
        "        ['A', 'movie', 'of', 'outstanding', 'brilliance', 'and', 'a', 'poignant', 'and', 'unusual', 'love' 'story'],\n",
        "        ['I', 'had', 'the', 'misfortune', 'to', 'watch', 'this', 'rubbish', 'on', 'Sky', 'Cinema', 'Max', 'in', 'a', 'cold', 'winter', 'night'],\n",
        "        ['I', 'am', 'at', 'a', 'distinct', 'disadvantage', 'here', 'I', 'have', 'not', 'seen', 'the', 'first', 'two', 'movies', 'in', 'this', 'series'],\n",
        "        ['This', 'program', 'is', 'a', 'lot', 'of', 'fun', 'and', 'the', 'title', 'song', 'is', 'so', 'catchy', 'I', 'can', 'not', 'get', 'it', 'out', 'of', 'my', 'head']\n",
        "]\n",
        "\n",
        "data['Word_Tokenization'] = tmp\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>Expanding_Abbreviations</th>\n",
              "      <th>Removing_Symbol</th>\n",
              "      <th>Word_Tokenization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>1</td>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>This was a great movie with a good cast all of...</td>\n",
              "      <td>[This, was, a, great, movie, with, a, good, ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Even if you're a huge Sandler fan, please don'...</td>\n",
              "      <td>0</td>\n",
              "      <td>Even if you are a huge Sandler fan, please do ...</td>\n",
              "      <td>Even if you are a huge Sandler fan please do n...</td>\n",
              "      <td>[Even, if, you, are, a, huge, Sandler, fan, pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>1</td>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>[A, movie, of, outstanding, brilliance, and, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>[I, had, the, misfortune, to, watch, this, rub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>0</td>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>I am at a distinct disadvantage here I have no...</td>\n",
              "      <td>[I, am, at, a, distinct, disadvantage, here, I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>1</td>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>[This, program, is, a, lot, of, fun, and, the,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                  Word_Tokenization\n",
              "0  This was a great movie with a good cast, all o...  ...  [This, was, a, great, movie, with, a, good, ca...\n",
              "1  Even if you're a huge Sandler fan, please don'...  ...  [Even, if, you, are, a, huge, Sandler, fan, pl...\n",
              "2  A movie of outstanding brilliance and a poigna...  ...  [A, movie, of, outstanding, brilliance, and, a...\n",
              "3  I had the misfortune to watch this rubbish on ...  ...  [I, had, the, misfortune, to, watch, this, rub...\n",
              "4  I am at a distinct disadvantage here. I have n...  ...  [I, am, at, a, distinct, disadvantage, here, I...\n",
              "5  This program is a lot of fun and the title son...  ...  [This, program, is, a, lot, of, fun, and, the,...\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVubkzIoJlUR"
      },
      "source": [
        "4.   **Case Folding**<br>\n",
        "Kata-kata yang sama tetapi memiliki case yang berbeda tidak dapat diidentifikasikan sebagai kata yang sama oleh sistem, misalnya kata \"The\" dan \"the\", nilai \"The\" == \"the\" akan bernilai False. Proses ini dilakukan guna memudahkan mendata banyaknya kata yang unik nantinya. Pada kesempatan kali ini, seluruh kata akan disamakan casenya menjadi lowercase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm_biaI0xgne"
      },
      "source": [
        "### Case Folding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I79utFR8v7AS",
        "outputId": "34364bb7-7a00-42df-e1e7-a9365d481f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "# membuat semua huruf menjadi huruf kecil\n",
        "tmp = [\n",
        "        ['this', 'was', 'a', 'great', 'movie', 'with', 'a', 'good', 'cast', 'all', 'of', 'them', 'hitting', 'on', 'all', 'cylinders'],\n",
        "        ['even', 'if', 'you', 'are', 'a', 'huge', 'sandler', 'fan', 'please', 'do', 'not', 'bother', 'with', 'this', 'extremely', 'disappointing', 'comedy'],\n",
        "        ['a', 'movie', 'of', 'outstanding', 'brilliance', 'and', 'a', 'poignant', 'and', 'unusual', 'love' 'story'],\n",
        "        ['i', 'had', 'the', 'misfortune', 'to', 'watch', 'this', 'rubbish', 'on', 'sky', 'cinema', 'max', 'in', 'a', 'cold', 'winter', 'night'],\n",
        "        ['i', 'am', 'at', 'a', 'distinct', 'disadvantage', 'here', 'i', 'have', 'not', 'seen', 'the', 'first', 'two', 'movies', 'in', 'this', 'series'],\n",
        "        ['this', 'program', 'is', 'a', 'lot', 'of', 'fun', 'and', 'the', 'title', 'song', 'is', 'so', 'catchy', 'I', 'can', 'not', 'get', 'it', 'out', 'of', 'my', 'head']\n",
        "]\n",
        "\n",
        "data['Case_Folding'] = tmp\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>Expanding_Abbreviations</th>\n",
              "      <th>Removing_Symbol</th>\n",
              "      <th>Word_Tokenization</th>\n",
              "      <th>Case_Folding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>1</td>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>This was a great movie with a good cast all of...</td>\n",
              "      <td>[This, was, a, great, movie, with, a, good, ca...</td>\n",
              "      <td>[this, was, a, great, movie, with, a, good, ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Even if you're a huge Sandler fan, please don'...</td>\n",
              "      <td>0</td>\n",
              "      <td>Even if you are a huge Sandler fan, please do ...</td>\n",
              "      <td>Even if you are a huge Sandler fan please do n...</td>\n",
              "      <td>[Even, if, you, are, a, huge, Sandler, fan, pl...</td>\n",
              "      <td>[even, if, you, are, a, huge, sandler, fan, pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>1</td>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>[A, movie, of, outstanding, brilliance, and, a...</td>\n",
              "      <td>[a, movie, of, outstanding, brilliance, and, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>[I, had, the, misfortune, to, watch, this, rub...</td>\n",
              "      <td>[i, had, the, misfortune, to, watch, this, rub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>0</td>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>I am at a distinct disadvantage here I have no...</td>\n",
              "      <td>[I, am, at, a, distinct, disadvantage, here, I...</td>\n",
              "      <td>[i, am, at, a, distinct, disadvantage, here, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>1</td>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>[This, program, is, a, lot, of, fun, and, the,...</td>\n",
              "      <td>[this, program, is, a, lot, of, fun, and, the,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                       Case_Folding\n",
              "0  This was a great movie with a good cast, all o...  ...  [this, was, a, great, movie, with, a, good, ca...\n",
              "1  Even if you're a huge Sandler fan, please don'...  ...  [even, if, you, are, a, huge, sandler, fan, pl...\n",
              "2  A movie of outstanding brilliance and a poigna...  ...  [a, movie, of, outstanding, brilliance, and, a...\n",
              "3  I had the misfortune to watch this rubbish on ...  ...  [i, had, the, misfortune, to, watch, this, rub...\n",
              "4  I am at a distinct disadvantage here. I have n...  ...  [i, am, at, a, distinct, disadvantage, here, i...\n",
              "5  This program is a lot of fun and the title son...  ...  [this, program, is, a, lot, of, fun, and, the,...\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdtDfIAUJn6Q"
      },
      "source": [
        "5.   **Stopword Removal**<br>\n",
        "Ada beberapa kata yang sering muncul dan tidak memberikan arti yang penting dan bermakna. Proses ini biasanya dilakukan dengan cara mengecek suatu kata apakah ada pada daftar stopword yang dipakai menjadi referensi. Apabila ada pada daftar stopword, maka kata tersebut akan dibuang. Pada kesempatan kali ini, proses ini akan dilakukan dengan membuang semua kata depan (*preposition*), kata ganti orang (*pronoun*), artikel (article), To Be, Adverb, kata hubung (*conjunction*), dan beberapa kata lain yang cukup tidak bermakna."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP6wOdt9yJen"
      },
      "source": [
        "### Stopword Removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrYx4zPsyNeH",
        "outputId": "be433ad8-760f-4543-f717-c20ae5f7f099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "# membuang kata-kata:\n",
        "# preposition = with, of, on, to, in, at\n",
        "# Adverb = even, not, here, so\n",
        "# pronoun = this, them, you, i, my\n",
        "# To Be = was, are, am\n",
        "# article = a, the\n",
        "# conjunction = if, and\n",
        "# others = have, had, can\n",
        "\n",
        "tmp = [\n",
        "        ['great', 'movie', 'good', 'cast', 'all', 'hitting', 'all', 'cylinders'],\n",
        "        ['huge', 'sandler', 'fan', 'please', 'bother', 'extremely', 'disappointing', 'comedy'],\n",
        "        ['movie', 'outstanding', 'brilliance', 'poignant', 'unusual', 'love', 'story'],\n",
        "        ['misfortune', 'watch', 'rubbish', 'sky', 'cinema', 'max', 'cold', 'winter', 'night'],\n",
        "        ['distinct', 'disadvantage', 'seen', 'first', 'two', 'movies', 'series'],\n",
        "        ['program', 'lot', 'fun', 'title', 'song', 'catchy', 'get', 'out', 'head']\n",
        "]\n",
        "\n",
        "data['StopWord_Removal'] = tmp\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>Expanding_Abbreviations</th>\n",
              "      <th>Removing_Symbol</th>\n",
              "      <th>Word_Tokenization</th>\n",
              "      <th>Case_Folding</th>\n",
              "      <th>StopWord_Removal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>1</td>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>This was a great movie with a good cast all of...</td>\n",
              "      <td>[This, was, a, great, movie, with, a, good, ca...</td>\n",
              "      <td>[this, was, a, great, movie, with, a, good, ca...</td>\n",
              "      <td>[great, movie, good, cast, all, hitting, all, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Even if you're a huge Sandler fan, please don'...</td>\n",
              "      <td>0</td>\n",
              "      <td>Even if you are a huge Sandler fan, please do ...</td>\n",
              "      <td>Even if you are a huge Sandler fan please do n...</td>\n",
              "      <td>[Even, if, you, are, a, huge, Sandler, fan, pl...</td>\n",
              "      <td>[even, if, you, are, a, huge, sandler, fan, pl...</td>\n",
              "      <td>[huge, sandler, fan, please, bother, extremely...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>1</td>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>[A, movie, of, outstanding, brilliance, and, a...</td>\n",
              "      <td>[a, movie, of, outstanding, brilliance, and, a...</td>\n",
              "      <td>[movie, outstanding, brilliance, poignant, unu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>[I, had, the, misfortune, to, watch, this, rub...</td>\n",
              "      <td>[i, had, the, misfortune, to, watch, this, rub...</td>\n",
              "      <td>[misfortune, watch, rubbish, sky, cinema, max,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>0</td>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>I am at a distinct disadvantage here I have no...</td>\n",
              "      <td>[I, am, at, a, distinct, disadvantage, here, I...</td>\n",
              "      <td>[i, am, at, a, distinct, disadvantage, here, i...</td>\n",
              "      <td>[distinct, disadvantage, seen, first, two, mov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>1</td>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>[This, program, is, a, lot, of, fun, and, the,...</td>\n",
              "      <td>[this, program, is, a, lot, of, fun, and, the,...</td>\n",
              "      <td>[program, lot, fun, title, song, catchy, get, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                   StopWord_Removal\n",
              "0  This was a great movie with a good cast, all o...  ...  [great, movie, good, cast, all, hitting, all, ...\n",
              "1  Even if you're a huge Sandler fan, please don'...  ...  [huge, sandler, fan, please, bother, extremely...\n",
              "2  A movie of outstanding brilliance and a poigna...  ...  [movie, outstanding, brilliance, poignant, unu...\n",
              "3  I had the misfortune to watch this rubbish on ...  ...  [misfortune, watch, rubbish, sky, cinema, max,...\n",
              "4  I am at a distinct disadvantage here. I have n...  ...  [distinct, disadvantage, seen, first, two, mov...\n",
              "5  This program is a lot of fun and the title son...  ...  [program, lot, fun, title, song, catchy, get, ...\n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9Db6auCJrfn"
      },
      "source": [
        "6.   **Lemmatization**<br>\n",
        "Kata-kata yang ada akan dikembalikan bentuk dasarnya dengan memperhatikan leksikalnya, misalnya \"ran\" menjadi \"run\". Ini bukan stemming sebab tidak hanya memotong prefix/suffix, tetapi memperhatikan leksikal dalam pengubahan kebentuk dasarnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHl4L0TUzN1j"
      },
      "source": [
        "### Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEqJltrezRlH",
        "outputId": "292c8dc0-2ec5-4343-dbc5-e348ecf83298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "# mengubah kata:\n",
        "# hitting ==> hit\n",
        "# cylinders ==> cylinder\n",
        "# disappointing ==> disappoint\n",
        "# seen ==> see\n",
        "# movies ==> movie\n",
        "\n",
        "tmp = [\n",
        "        ['great', 'movie', 'good', 'cast', 'all', 'hit', 'all', 'cylinder'],\n",
        "        ['huge', 'sandler', 'fan', 'please', 'bother', 'extremely', 'disappoint', 'comedy'],\n",
        "        ['movie', 'outstanding', 'brilliance', 'poignant', 'unusual', 'love', 'story'],\n",
        "        ['misfortune', 'watch', 'rubbish', 'sky', 'cinema', 'max', 'cold', 'winter', 'night'],\n",
        "        ['distinct', 'disadvantage', 'see', 'first', 'two', 'movie', 'series'],\n",
        "        ['program', 'lot', 'fun', 'title', 'song', 'catchy', 'get', 'out', 'head']\n",
        "]\n",
        "\n",
        "data['clean'] = tmp\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>Expanding_Abbreviations</th>\n",
              "      <th>Removing_Symbol</th>\n",
              "      <th>Word_Tokenization</th>\n",
              "      <th>Case_Folding</th>\n",
              "      <th>StopWord_Removal</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>1</td>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>This was a great movie with a good cast all of...</td>\n",
              "      <td>[This, was, a, great, movie, with, a, good, ca...</td>\n",
              "      <td>[this, was, a, great, movie, with, a, good, ca...</td>\n",
              "      <td>[great, movie, good, cast, all, hitting, all, ...</td>\n",
              "      <td>[great, movie, good, cast, all, hit, all, cyli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Even if you're a huge Sandler fan, please don'...</td>\n",
              "      <td>0</td>\n",
              "      <td>Even if you are a huge Sandler fan, please do ...</td>\n",
              "      <td>Even if you are a huge Sandler fan please do n...</td>\n",
              "      <td>[Even, if, you, are, a, huge, Sandler, fan, pl...</td>\n",
              "      <td>[even, if, you, are, a, huge, sandler, fan, pl...</td>\n",
              "      <td>[huge, sandler, fan, please, bother, extremely...</td>\n",
              "      <td>[huge, sandler, fan, please, bother, extremely...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>1</td>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>[A, movie, of, outstanding, brilliance, and, a...</td>\n",
              "      <td>[a, movie, of, outstanding, brilliance, and, a...</td>\n",
              "      <td>[movie, outstanding, brilliance, poignant, unu...</td>\n",
              "      <td>[movie, outstanding, brilliance, poignant, unu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>[I, had, the, misfortune, to, watch, this, rub...</td>\n",
              "      <td>[i, had, the, misfortune, to, watch, this, rub...</td>\n",
              "      <td>[misfortune, watch, rubbish, sky, cinema, max,...</td>\n",
              "      <td>[misfortune, watch, rubbish, sky, cinema, max,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>0</td>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>I am at a distinct disadvantage here I have no...</td>\n",
              "      <td>[I, am, at, a, distinct, disadvantage, here, I...</td>\n",
              "      <td>[i, am, at, a, distinct, disadvantage, here, i...</td>\n",
              "      <td>[distinct, disadvantage, seen, first, two, mov...</td>\n",
              "      <td>[distinct, disadvantage, see, first, two, movi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>1</td>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>[This, program, is, a, lot, of, fun, and, the,...</td>\n",
              "      <td>[this, program, is, a, lot, of, fun, and, the,...</td>\n",
              "      <td>[program, lot, fun, title, song, catchy, get, ...</td>\n",
              "      <td>[program, lot, fun, title, song, catchy, get, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                              clean\n",
              "0  This was a great movie with a good cast, all o...  ...  [great, movie, good, cast, all, hit, all, cyli...\n",
              "1  Even if you're a huge Sandler fan, please don'...  ...  [huge, sandler, fan, please, bother, extremely...\n",
              "2  A movie of outstanding brilliance and a poigna...  ...  [movie, outstanding, brilliance, poignant, unu...\n",
              "3  I had the misfortune to watch this rubbish on ...  ...  [misfortune, watch, rubbish, sky, cinema, max,...\n",
              "4  I am at a distinct disadvantage here. I have n...  ...  [distinct, disadvantage, see, first, two, movi...\n",
              "5  This program is a lot of fun and the title son...  ...  [program, lot, fun, title, song, catchy, get, ...\n",
              "\n",
              "[6 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_UvYFs8fTtz"
      },
      "source": [
        "# Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbg84N_k2Oj3"
      },
      "source": [
        "Menghitung ada berapa banyak kata berbeda/unik yang ada pada data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HKkBmf3ij1K",
        "outputId": "db683046-6a09-485f-8116-b752a0a59d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#memasukan semua kata ke dalam set dan mengetahui banyaknya kata unik\n",
        "vocab = set()\n",
        "for review in data['clean']:\n",
        "  for word in review:\n",
        "    vocab.add(word)\n",
        "unique_word = len(vocab)\n",
        "print('Unique Word: ', len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique Word:  45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrbDg_m62Wvq"
      },
      "source": [
        "Mencatat pemetaan kata. Misalnya dalam `vocab` berisi `['cat','dog','fish']` (isi set otomatis terurut) maka: \n",
        "*   `'cat'` akan tercatat sebagai `'0' `dan` '0'` dicatat merepresentasikan `'cat'`\n",
        "*   `'dog' `akan tercatat sebagai `'1'` dan `'1'` dicatat merepresentasikan `'dog'`\n",
        "*   `'fish'` akan tercatat sebagai `'2'` dan `'2' `dicatat merepresentasikan `'fish'`\n",
        "\n",
        "catatan dari id ke kata yang disimpan pada `id_word`<br>\n",
        "catatan dari kata ke id yang disimpan pada `word_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no_0qxXDkZuv"
      },
      "source": [
        "#mencatat mapping id ke katanya dan kata ke id nya\n",
        "word_id = dict()\n",
        "id_word = dict()\n",
        "for id,w in enumerate(vocab):\n",
        "  word_id[w] = id\n",
        "  id_word[id] = w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_vuhasj3Xd-"
      },
      "source": [
        "Untuk setiap review, dibuat encoding berupa list 0 1 yang panjangnya adalah banyak kata unik yang ada pada keseluruhan data. Untuk  posisi id kata yang ada pada suatu review akan di lambangkan dengan 1, dan kata yang tidak ada dilambangkan dengan 0. Urutan posisi sesuai id kata tersebut."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbsVSGxVjGRC",
        "outputId": "c65329b8-78a4-44d0-eb86-46e396c3e874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "# merepresentasikan review data menjadi one-hot encoding\n",
        "tmp = []\n",
        "for review in data['clean']:\n",
        "  bar = []\n",
        "  for id,w in enumerate(vocab):\n",
        "    if w in review:\n",
        "      bar.append(1)\n",
        "    else:\n",
        "      bar.append(0)\n",
        "  tmp.append(bar)\n",
        "data['encoded'] = tmp\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>Expanding_Abbreviations</th>\n",
              "      <th>Removing_Symbol</th>\n",
              "      <th>Word_Tokenization</th>\n",
              "      <th>Case_Folding</th>\n",
              "      <th>StopWord_Removal</th>\n",
              "      <th>clean</th>\n",
              "      <th>encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>1</td>\n",
              "      <td>This was a great movie with a good cast, all o...</td>\n",
              "      <td>This was a great movie with a good cast all of...</td>\n",
              "      <td>[This, was, a, great, movie, with, a, good, ca...</td>\n",
              "      <td>[this, was, a, great, movie, with, a, good, ca...</td>\n",
              "      <td>[great, movie, good, cast, all, hitting, all, ...</td>\n",
              "      <td>[great, movie, good, cast, all, hit, all, cyli...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Even if you're a huge Sandler fan, please don'...</td>\n",
              "      <td>0</td>\n",
              "      <td>Even if you are a huge Sandler fan, please do ...</td>\n",
              "      <td>Even if you are a huge Sandler fan please do n...</td>\n",
              "      <td>[Even, if, you, are, a, huge, Sandler, fan, pl...</td>\n",
              "      <td>[even, if, you, are, a, huge, sandler, fan, pl...</td>\n",
              "      <td>[huge, sandler, fan, please, bother, extremely...</td>\n",
              "      <td>[huge, sandler, fan, please, bother, extremely...</td>\n",
              "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>1</td>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>A movie of outstanding brilliance and a poigna...</td>\n",
              "      <td>[A, movie, of, outstanding, brilliance, and, a...</td>\n",
              "      <td>[a, movie, of, outstanding, brilliance, and, a...</td>\n",
              "      <td>[movie, outstanding, brilliance, poignant, unu...</td>\n",
              "      <td>[movie, outstanding, brilliance, poignant, unu...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>I had the misfortune to watch this rubbish on ...</td>\n",
              "      <td>[I, had, the, misfortune, to, watch, this, rub...</td>\n",
              "      <td>[i, had, the, misfortune, to, watch, this, rub...</td>\n",
              "      <td>[misfortune, watch, rubbish, sky, cinema, max,...</td>\n",
              "      <td>[misfortune, watch, rubbish, sky, cinema, max,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>0</td>\n",
              "      <td>I am at a distinct disadvantage here. I have n...</td>\n",
              "      <td>I am at a distinct disadvantage here I have no...</td>\n",
              "      <td>[I, am, at, a, distinct, disadvantage, here, I...</td>\n",
              "      <td>[i, am, at, a, distinct, disadvantage, here, i...</td>\n",
              "      <td>[distinct, disadvantage, seen, first, two, mov...</td>\n",
              "      <td>[distinct, disadvantage, see, first, two, movi...</td>\n",
              "      <td>[0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>1</td>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>This program is a lot of fun and the title son...</td>\n",
              "      <td>[This, program, is, a, lot, of, fun, and, the,...</td>\n",
              "      <td>[this, program, is, a, lot, of, fun, and, the,...</td>\n",
              "      <td>[program, lot, fun, title, song, catchy, get, ...</td>\n",
              "      <td>[program, lot, fun, title, song, catchy, get, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                            encoded\n",
              "0  This was a great movie with a good cast, all o...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...\n",
              "1  Even if you're a huge Sandler fan, please don'...  ...  [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...\n",
              "2  A movie of outstanding brilliance and a poigna...  ...  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...\n",
              "3  I had the misfortune to watch this rubbish on ...  ...  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, ...\n",
              "4  I am at a distinct disadvantage here. I have n...  ...  [0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...\n",
              "5  This program is a lot of fun and the title son...  ...  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, ...\n",
              "\n",
              "[6 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fkfhflk4Kvt"
      },
      "source": [
        "## Center Word dan Context Word\n",
        "\n",
        "Pada kesempatan ini, digunakan metode **SKIP-GRAM**, yang mana dari sebuah Center Word sebagai input akan dipetakan memiliki beberapa Context Word yang masih beradap ada 1 window sebagai output yang idealnya. Misalkan Center Word adalah w(t) dan windownya adalah 5 (2 sebelum dan 2 sesudah Center Word), maka output yang ideal adalah w(t-1), w(t-2), w(t+1), dan w(t+2). Untuk lebih jelasnya dapat dilihat pada gambar berikut.<br><br>\n",
        "![alt text](https://i.ibb.co/yhgHtVm/text-example-1.png)<br><br>\n",
        "\n",
        "Untuk setiap input dan output (Center Word dan Context Word) direpresentasikan dalam bentuk one-hot encoding. Ini berarti ada sebuah vektor dengan panjang v dimana v adalah banyaknya kata unik pada data. Setiap posisi pada vektor berhubungan dengan sebuah kata tertentu, sehingga jika ingin merepresentasikan sebuah kata, maka seluruh nilai vektor ini 0 kecuali pada posisi yang merepresentasikan kata tersebut. Pada gambar dibawah ini menggambarkan bagaimana kasus #1, #5, dan #9 di representasikan pada one-hot encoding.<br><br>\n",
        "![alt text](https://i.ibb.co/9vRVzX3/training-data-1.png)<br><br>\n",
        "\n",
        "Ringkasan:\n",
        "*   Setiap input adalah sebuah Center Word yang telah di encoding pada vektor berukuran v, yakni banyaknya kata unik pada data\n",
        "*   Setiap output adalah kumpulan beberapa Context Word yang telah di encoding pada vektor berukuran v, yakni banyaknya kata unik pada data\n",
        "\n",
        "Misalnya untuk kasus #1, maka:\n",
        "*   input vektor = [0,0,0,0,0,0,0,1]\n",
        "*   output vektor = [1,0,0,0,0,0,1,0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9guiU1BykQ5s"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "window = 2\n",
        "\n",
        "#untuk setiap word di vocab di cari context word-nya\n",
        "for w in vocab:\n",
        "  # menyiapkan vektor yang isinya 0 semua\n",
        "  bar_in = [0]*unique_word\n",
        "  bar_out = [0]*unique_word\n",
        "  # tandai id dari center word\n",
        "  bar_in[word_id[w]] = 1\n",
        "  for review in data['clean']:\n",
        "    for id,v in enumerate(review):\n",
        "      if w == v:\n",
        "        # mencari context word\n",
        "        for pointer in range(max(0,id-window),min(len(review),id+window+1)):\n",
        "          if id == pointer: continue\n",
        "          # tandai id dari context word\n",
        "          bar_out[ word_id[review[pointer]] ] = 1\n",
        "  X.append(bar_in)\n",
        "  Y.append(bar_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFvBLbG-wSvD"
      },
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAXNtWAxDlbb"
      },
      "source": [
        "## Arsitektur Neural Network Word Embedding\n",
        "\n",
        "![alt text](https://i.ibb.co/yf9JkzV/Skip-gram-architecture-2-1.jpg)<br><br>\n",
        "\n",
        "*    Banyaknya data pada dataset adalah banyaknya Center Word yang ada\n",
        "*   Input layer memiliki neuron sebanyak V, yakni banyaknya kata unik yang ada pada data\n",
        "*   Hidden layer memliki neuron sebanyak N, yakni banyaknya fitur/dimensi vektor yang diinginkan untuk merepresentasikan suatu kata nantinya\n",
        "*   Output layer memiliki neuron sebanyak V, yakni banyaknya kata unik yang ada pada data\n",
        "*   Banyaknya epcoh/iterasi sebanyak data pada dataset x 1000, sehingga setiap data pada dataset nantinya akan 1000 kali ditrain pada model ini\n",
        "*   Learning rate adalah 0.001\n",
        "*   Fungsi aktivasi pada input-hidden adalah linear dan fungsi aktivasi pada hidden-output adalah softmax\n",
        "* Weight di inisialisasi secara random dengan nilai mendekati 0\n",
        "* Weight input-hidden yang nantinya akan digunakan sebagai hasil word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5UbCNhAycSS"
      },
      "source": [
        "input_layer = unique_word\n",
        "hidden_layer = 3\n",
        "output_layer = unique_word\n",
        "\n",
        "epoch = len(X) * 1000\n",
        "lr = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap8eGndyFb13"
      },
      "source": [
        "Fungsi aktivasi Softmax<br><br>\n",
        "$$ \n",
        "softmax(x_i)=\\frac{exp(x_i)}{\\sum_{j}^{len(x_i)}{ exp(x_j))}}\n",
        "$$\n",
        "<br><br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wziws6EnwlGy"
      },
      "source": [
        "def softmax(x):\n",
        "  e_x = np.exp(x - np.max(x)) \n",
        "  return e_x / e_x.sum(axis=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie__eZN7RAe_"
      },
      "source": [
        "Inisialisasi Weight secara random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmRownQxwzuM"
      },
      "source": [
        "# nilai random ada apa range [0..1] sehingga untuk menginisialisasi nilai yang berada pada rata-rata 0 (ada nilai yang + dan ada yang -), nilai random*2 -1\n",
        "# contohnya:\n",
        "# bila nilai randon adalah 0.3 , maka nilai yang di inisialisasi adalah 0.3*2-1 = -0.4\n",
        "# bila nilai randon adalah 0.8 , maka nilai yang di inisialisasi adalah 0.8*2-1 = +0.6\n",
        "\n",
        "W1 = 2*np.random.random((input_layer,hidden_layer)) - 1\n",
        "W2 = 2*np.random.random((hidden_layer,output_layer)) - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjSJykj1RIHA"
      },
      "source": [
        "**Berikut ini adalah beberapa perhitungan/rumus yang digunakan dalam perhitungan Neural Network:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG9Z-lXpRTNC"
      },
      "source": [
        "Feed forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjcoTvcQMQ_r"
      },
      "source": [
        "$$\\begin{eqnarray}\n",
        "\\textbf{h} =  W_1^T.X \\nonumber \\\\\n",
        "\\end{eqnarray}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkERNaXEMU6B"
      },
      "source": [
        "$$\\begin{eqnarray}\n",
        "\\textbf{u} =  W_2^T.W_1^T.X \\nonumber \\\\\n",
        "\\end{eqnarray} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ckQA3e1MhbX"
      },
      "source": [
        "$$\n",
        "\\begin{eqnarray}\n",
        "\\textbf{y}= \\mathbb{S}\\textrm{oftmax}(\\textbf{u})\\nonumber\\\\\n",
        "\\end{eqnarray}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsxFkFGWRYZ4"
      },
      "source": [
        "Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_imjSnxOofk"
      },
      "source": [
        "$$\\begin{eqnarray}\n",
        "e = y - t \\nonumber \\\\\n",
        "\\end{eqnarray}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gEBV8dCRbGH"
      },
      "source": [
        "Turunan Cost Function terhadap Weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWuAqUcjMl3z"
      },
      "source": [
        "$$\\begin{equation}\n",
        "{\n",
        "\\frac{\\partial E}{\\partial W_2} = e.h\n",
        "}\n",
        "\\end{equation}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaBqv5SzOcoq"
      },
      "source": [
        "$$\\begin{equation}\n",
        "{\n",
        "\\frac{\\partial E}{\\partial W_1} = e . W_1 . X\n",
        "}\n",
        "\\end{equation}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh7h_CP_RiZ1"
      },
      "source": [
        "Update Weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leszIVBtPgsM"
      },
      "source": [
        "$$\\begin{eqnarray}\n",
        "W_{1_{new}} = W_{1_{old}} - \\alpha {\\frac{\\partial E}{\\partial W_1} }\n",
        "\\end{eqnarray}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S77uooK0QDKk"
      },
      "source": [
        "$$\\begin{eqnarray}\n",
        "W_{2_{new}} = W_{2_{old}} - \\alpha {\\frac{\\partial E}{\\partial W_2} }\n",
        "\\end{eqnarray}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQQ0voyeRlZc"
      },
      "source": [
        "Men-training Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imNYQ5hTylIO"
      },
      "source": [
        "for i in range(epoch):\n",
        "  # menentukan input dan target\n",
        "  x = X[i % len(X)]\n",
        "  t = Y[i % len(X)]\n",
        "\n",
        "  # feed forward\n",
        "  h = np.dot(W1.T, x).reshape(hidden_layer,1)\n",
        "  u = np.dot(W2.T, h)\n",
        "  y =  softmax(u)\n",
        "\n",
        "  # error\n",
        "  e = y - np.asarray(t).reshape(output_layer,1) \n",
        "\n",
        "  # menghitung gradien/turunan\n",
        "  dW2 = np.dot(h, e.T)\n",
        "  xx = np.array(x).reshape(input_layer,1)\n",
        "  dW1 = np.dot(xx , np.dot(W2, e).T)\n",
        "\n",
        "  # update Weight\n",
        "  new_W1 = W1 - lr * dW1\n",
        "  new_W2 = W2 - lr * dW2\n",
        "\n",
        "  W1 = new_W1\n",
        "  W2 = new_W2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQGczvpLRspi"
      },
      "source": [
        "Hasil dari Word Embedding dengan ukuran matrix (banyak kata unik x banyak fitur)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsKpoBbGR3Va",
        "outputId": "97e19406-62c8-4b3c-c1cf-4db6f0783db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "W1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6EkAYRTQdbJ",
        "outputId": "ca912ec7-6724-44aa-9b6f-06cd27f3b379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        }
      },
      "source": [
        "W1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -5.71918214,  -2.0546574 ,  -4.3683308 ],\n",
              "       [ -3.88293208,  -0.97312426,  -8.7957914 ],\n",
              "       [ -1.5211889 ,  -2.80543737,  -8.29175142],\n",
              "       [ -4.28971135,   2.5165835 ,  -0.90049805],\n",
              "       [ -2.37712317,   2.7596082 ,  -0.32214968],\n",
              "       [ -1.38751889,  -0.80222148,  -8.14717108],\n",
              "       [  0.76678237,   3.16933232,  -0.76685267],\n",
              "       [ -0.15508243,  -6.50101803,   0.61145767],\n",
              "       [ -1.51733083,   0.85041503,   0.28972073],\n",
              "       [  0.1740655 ,   1.08472119,  -6.70479625],\n",
              "       [ -0.36782389,   2.48899681,  -2.87508487],\n",
              "       [  2.10712202,   0.65069504,   1.54104906],\n",
              "       [ -3.42453713,  -0.24526313,  -5.50783475],\n",
              "       [  0.29581643,  -0.5677209 ,   1.36740417],\n",
              "       [ -4.36120394,   1.38919667,  -4.06867858],\n",
              "       [  0.0557423 ,   2.31340169,  -2.19917305],\n",
              "       [ -0.70213025,  -1.21794235,  -1.97874338],\n",
              "       [ -0.39961762,  -2.54218315,   0.8932584 ],\n",
              "       [  0.54924454,  -0.81123961,  -2.10601415],\n",
              "       [ -2.0141261 ,   1.3516119 ,   0.20585248],\n",
              "       [  3.25227345,   0.13975629,  -0.72294852],\n",
              "       [  0.93276418,  -0.75616603,  -2.85780168],\n",
              "       [  0.37409605,  -5.01872349,   1.74388909],\n",
              "       [ -0.05688782,   1.37023852,  -0.52068842],\n",
              "       [ -4.57474581,   2.43323054,   0.33309196],\n",
              "       [  0.80643125,  -0.92753385,  -0.53576584],\n",
              "       [  0.96274933,  -3.47219852,  -1.55939329],\n",
              "       [  0.03442429,  -2.37251985,  -0.38647324],\n",
              "       [ -2.52881284,   1.38386452,  -0.53857818],\n",
              "       [  1.26687047,  -2.39450801,   0.26470917],\n",
              "       [ -2.43778202,  -0.04352855,   0.47759134],\n",
              "       [ -3.05828267,   1.45766443,  -3.4846751 ],\n",
              "       [ -5.91838823,   1.58489966,   0.87404646],\n",
              "       [ -4.96524186,   2.69372612,  -2.54415393],\n",
              "       [ -2.76227746,   1.27242992,   0.77662755],\n",
              "       [ -2.44845509,   1.47577527,  -3.12003221],\n",
              "       [  0.56352431,  -0.69193041,   1.61087692],\n",
              "       [  0.23068393,  -2.27636387,  -0.29202698],\n",
              "       [ -1.54081551,  -1.460742  ,  -3.22568043],\n",
              "       [  1.63703442,  -4.01351039,   1.59862079],\n",
              "       [ -3.07742821,   2.74884178,  -3.95602421],\n",
              "       [  2.06175287,  -3.24481801,  -0.24813148],\n",
              "       [-14.43596013,  -0.90850056, -11.47905997],\n",
              "       [  0.06939608,   0.16444997,   1.66571447],\n",
              "       [  1.53172283,  -4.06153415,   1.70329543]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOgtYuXEUyEy"
      },
      "source": [
        "Mencoba memprediksi Context Word dari Center Word yang diberikan, misalnya:<br>\n",
        "Center Word : \"**sky**\"\n",
        "\n",
        "yang ada pada kalimat:<br>\n",
        "\"I had the misfortune to watch this rubbish on Sky Cinema Max in a cold winter night\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE-Gkp0gUypH",
        "outputId": "e4e17642-5188-4a31-cb8f-41b9ce3431be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "word_id[\"sky\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xCcZugcU9ps"
      },
      "source": [
        "#one-hot encoding input\n",
        "x = [0]* unique_word\n",
        "x[word_id[\"sky\"]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgAnPE1mUpGY",
        "outputId": "cc130343-41bc-4641-cb47-f103ece15d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "# feed forward \n",
        "h = np.dot(W1.T, x).reshape(hidden_layer,1)\n",
        "u = np.dot(W2.T, h)\n",
        "\n",
        "y =  softmax(u)\n",
        "\n",
        "# cari nilai prediksi yang paling tinggi sebanyak window\n",
        "tmp =[]\n",
        "\n",
        "for i,pred in enumerate(y):\n",
        "  tmp.append([pred[0],i])\n",
        "tmp.sort(reverse=True)\n",
        "\n",
        "print(tmp)\n",
        "\n",
        "for i in range(window*2):\n",
        "  print(id_word[tmp[i][1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.47936893511237255, 43], [0.150901327348412, 41], [0.13980658350649153, 6], [0.12132430759512122, 25], [0.03264646591707455, 7], [0.024630216941109524, 18], [0.01999948323764516, 16], [0.018585935950542982, 9], [0.008913970388703582, 21], [0.001613357736389894, 5], [0.0005640675220450106, 22], [0.000447910498915712, 39], [0.0003787783351509097, 37], [0.00021888387451604078, 20], [0.00012944115794656942, 29], [0.0001254767308160298, 27], [7.842362084207141e-05, 17], [7.702854174916512e-05, 0], [4.447792883107396e-05, 36], [4.030785407438168e-05, 26], [3.921222352086833e-05, 30], [3.447749570779437e-05, 44], [1.6201708579781767e-05, 11], [7.722585851218175e-06, 15], [5.9308503329525e-06, 13], [8.928447894709269e-07, 28], [7.248231401774868e-08, 34], [3.376877118727969e-08, 2], [2.5821803972476288e-08, 42], [2.4521284984188287e-08, 33], [1.2979264464092915e-08, 10], [6.092340068727085e-09, 23], [5.057391237481542e-09, 1], [1.2073630906997625e-09, 32], [3.41844444399001e-10, 8], [6.520212906541508e-11, 38], [5.4254277725971485e-11, 14], [3.6601162912090044e-11, 24], [2.048892405286504e-11, 3], [1.8687576657849418e-11, 35], [8.477619644979487e-12, 4], [5.2685617926910904e-12, 12], [5.215472691684968e-12, 31], [4.021902430586832e-12, 19], [1.872840466232175e-12, 40]]\n",
            "watch\n",
            "cinema\n",
            "rubbish\n",
            "max\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmEDklAc-8W8"
      },
      "source": [
        "word_embedding = W1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0vcUj_MkjGp"
      },
      "source": [
        "Context Words yang dihasilkan telah sesuai, walaupun pada kalimat \"I had the misfortune to watch this rubbish on Sky Cinema Max in a cold winter night\", kata yang berdekatan (windows 2 sedudah dan 2 sebelum) dengan \"Sky\" adalah \"rubbish\", \"on\", \"Cinema\", dan \"Max\", tetapi karena sudah dilakukan preprocessing kalimat tersebut sudah menjadi \"misfortune watch rubbish sky cinema max cold winter night\", sehingga Context Words dari \"Sky\" adalah \"**watch**\", \"**rubbish**\", \"**cinema**\", dan \"**max**\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCZv5558fY1M"
      },
      "source": [
        "# BPNN (Sentiment Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXKnFczumCxA"
      },
      "source": [
        "**Mempersiapkan Input**<br><br>\n",
        "\n",
        "Input pada BPNN terdiri dari neuron sebanyak:<br>\n",
        "**maximal banyak kata pada setiap data yang telah di prepocessing x fitur/dimensi word embedding**\n",
        "\n",
        "Pada kesempatan ini, banyak kata maksimal pada seluruh data adalah 9 dan fitur word embedding adalah 3, sehingga<br><br>\n",
        "\n",
        "Input layer memiliki 27 (9 x 3) neuron<br>\n",
        "\n",
        "*   neuruon 1 sampai 3 digunakan untuk fitur word embedding kata ke-1\n",
        "*   neuruon 4 sampai 6 digunakan untuk fitur word embedding kata ke-2\n",
        "*   neuruon 7 sampai 9 digunakan untuk fitur word embedding kata ke-3\n",
        "*   neuruon 10 sampai 12 digunakan untuk fitur word embedding kata ke-4\n",
        "*   neuruon 13 sampai 15 digunakan untuk fitur word embedding kata ke-5\n",
        "*   neuruon 16 sampai 18 digunakan untuk fitur word embedding kata ke-6\n",
        "*   neuruon 19 sampai 21 digunakan untuk fitur word embedding kata ke-7\n",
        "*   neuruon 22 sampai 24 digunakan untuk fitur word embedding kata ke-8\n",
        "*   neuruon 25 sampai 27 digunakan untuk fitur word embedding kata ke-9\n",
        "<br><br>\n",
        "\n",
        "Apabila sebuah data memiliki kata kurang dari 9, maka neuron untuk kata tersebut adalah nol (0)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX94N7QlA6U7",
        "outputId": "dbdc816e-c8bb-4877-be3b-7bba96ac0595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# mencari banyak kata terbanyak pada setiap baris data\n",
        "max_inp = 0\n",
        "for review in data['clean']:\n",
        "  max_inp = max(max_inp,len(review))\n",
        "max_inp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTutDF-D5-51"
      },
      "source": [
        "# mempersiapkan input seperti pada penjelasan di atas\n",
        "input_bpnn = []\n",
        "for num in range(len(data)):\n",
        "  features = []\n",
        "  for id in range(unique_word):\n",
        "    # membaca encoding data\n",
        "    if data['encoded'][num][id] == 1:\n",
        "      # apa bila encoding 1, artinya kata pada posisi tersebut ada pada baris data tersebut, sehingga fitur word embedingnnya dipakai\n",
        "      for w in word_embedding[id]:\n",
        "        features.append(w)\n",
        "  # membuat panjang vektor sama semua (sesuai banyaknya kata maksimal)\n",
        "  features.extend([0] * (max_inp*word_embedding.shape[1] - len(features)))\n",
        "  input_bpnn.append(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvgb-7WWBZQE",
        "outputId": "473e2956-b9a2-48f3-d587-bc57c04f2430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_bpnn = np.array(input_bpnn)\n",
        "input_bpnn.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU61fziboX5C"
      },
      "source": [
        "**Mempersiapkan Output** <br><br>\n",
        "\n",
        "Output layer terdiri dari 1 neuron yang memiliki nilai [0..1]. Nilai pembulatan (>=0.5 menjadi 1, <0.5 menjadi 0) digunakan sebagai hasil akhir yang akan di bandingkan dengan target untuk mengevaluasi model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqDxfT0aWw02",
        "outputId": "4e1ab2cc-e863-44d4-f5bd-91e53024b1e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "output_bpnn = np.array(data['label'])\n",
        "output_bpnn.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D91OGJHHo6lY"
      },
      "source": [
        "Fungsi Aktivasi Sigmoid<br>\n",
        "\n",
        "$$ Sigmoid(x) = \\frac{1} {1 + e^{-x}} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQO7tqQ0HqmC"
      },
      "source": [
        "def sigmoid(x,deriv=False):\n",
        "    if(deriv==True):\n",
        "        return x*(1-x)\n",
        "    return 1/(1+np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NYTK_38ssMq"
      },
      "source": [
        "**Arsitektur Backpropagation Neural Network** <br><br>\n",
        "![alt text](https://i.ibb.co/w6rMYyQ/Presentation1.jpg)\n",
        "<br><br>\n",
        "*   Input Layer = 27 neuron\n",
        "*   Hidden Layer = 25 neuron\n",
        "*   Output Layer = 1 neuron\n",
        "*   Epoch = 1000 untuk setiap data\n",
        "*   Learning Rate = 0.5\n",
        "*   Weight diinisialisasi secara random mendekati 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pteLRkaft7wG"
      },
      "source": [
        "Beberapa perhitungan/rumus yang digunakan pada model ini:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrziFt7vuGn-"
      },
      "source": [
        "Feed forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mOnM-RtuGoA"
      },
      "source": [
        "$$\\begin{eqnarray}\n",
        "\\textbf{h}=W_1^T.X \\nonumber \\\\\n",
        "\\end{eqnarray}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzeNBwS8uQVI"
      },
      "source": [
        "$$\n",
        "\\begin{eqnarray}\n",
        "\\textbf{g}= \\textrm{Sigmoid}(\\textbf{h})\\nonumber\\\\\n",
        "\\end{eqnarray}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8t_drrguGoB"
      },
      "source": [
        "$$\\begin{eqnarray}\n",
        "\\textbf{u} =  W_2^T.g \\nonumber \\\\\n",
        "\\end{eqnarray} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuQ2DLlYuGoC"
      },
      "source": [
        "$$\n",
        "\\begin{eqnarray}\n",
        "\\textbf{y}= \\textrm{Sigmoid}(\\textbf{u})\\nonumber\\\\\n",
        "\\end{eqnarray}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94T6A7xhuGoD"
      },
      "source": [
        "Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_M74YluuGoE"
      },
      "source": [
        "$$\\begin{eqnarray}\n",
        "e = y - t \\nonumber \\\\\n",
        "\\end{eqnarray}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jugdDiRauGoF"
      },
      "source": [
        "Turunan Cost Function terhadap Weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z_rIaBEuGoG"
      },
      "source": [
        "$$\\begin{equation}\n",
        "{\n",
        "\\frac{\\partial E}{\\partial W_2} = e. y . (1-y). g\n",
        "}\n",
        "\\end{equation}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXSXUvJHuGoH"
      },
      "source": [
        "$$\\begin{equation}\n",
        "{\n",
        "\\frac{\\partial E}{\\partial W_1} = x . e. y . (1-y) . W_2^T . g . (1-g)\n",
        "}\n",
        "\\end{equation}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac8NQ-G2uGoI"
      },
      "source": [
        "Update Weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNLH9zycuGoJ"
      },
      "source": [
        "$$\\begin{eqnarray}\n",
        "W_{1_{new}} = W_{1_{old}} - \\alpha {\\frac{\\partial E}{\\partial W_1} }\n",
        "\\end{eqnarray}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xISFJFXYuGoK"
      },
      "source": [
        "$$\\begin{eqnarray}\n",
        "W_{2_{new}} = W_{2_{old}} - \\alpha {\\frac{\\partial E}{\\partial W_2} }\n",
        "\\end{eqnarray}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHXcCMetCcvc"
      },
      "source": [
        "input_layer = input_bpnn.shape[1]\n",
        "hidden_layer = 25\n",
        "output_layer = 1\n",
        "\n",
        "epoch = input_bpnn.shape[0] * 10000\n",
        "lr = 0.005"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMMN-3kWB0Jm"
      },
      "source": [
        "# nilai random ada apa range [0..1] sehingga untuk menginisialisasi nilai yang berada pada rata-rata 0 (ada nilai yang + dan ada yang -), nilai random*2 -1\n",
        "# contohnya:\n",
        "# bila nilai randon adalah 0.3 , maka nilai yang di inisialisasi adalah 0.3*2-1 = -0.4\n",
        "# bila nilai randon adalah 0.8 , maka nilai yang di inisialisasi adalah 0.8*2-1 = +0.6\n",
        "W1 = 2*np.random.random((input_layer,hidden_layer)) - 1\n",
        "W2 = 2*np.random.random((hidden_layer,output_layer)) - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5I-jHFAtS83"
      },
      "source": [
        "Men-training model BPNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndd-uGtc52bz"
      },
      "source": [
        "** pada proses training ini, digunana 66.7% dari data yakni 4 data pertama, 2 data yang lain menjadi data yang belum pernah diketahui model dan akan digunakan saat evaluation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7wlxkM2HecC",
        "outputId": "a996fae9-d82e-446f-b228-2719da3e7be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(epoch):\n",
        "  # siapkan input dan target\n",
        "  x = input_bpnn[i % (len(input_bpnn)-2)]\n",
        "  t = output_bpnn[i %(len(input_bpnn)-2)]\n",
        "\n",
        "  # feed forward\n",
        "  h = np.dot(W1.T, x)\n",
        "  g = sigmoid(h)\n",
        "  u = np.dot(W2.T, g)\n",
        "  y =  sigmoid(u)\n",
        "\n",
        "  # error\n",
        "  e = y - t\n",
        "\n",
        "  # print loss setiap epoch kelipatan 1000 (loss :: MAE)\n",
        "  if (i+1)%1000 == 0: print('loss: ',np.mean(np.abs(e)), 'epoch : ',i+1 )\n",
        "\n",
        "  # hitung gradient/turunan\n",
        "  dW2 = e * sigmoid(y,True)\n",
        "  eh = dW2.dot(W2.T)\n",
        "  dW1 = eh * sigmoid(g,True)\n",
        "  \n",
        "  # perbaruhi Weight\n",
        "  new_W2 = W2 - g.reshape(g.shape[0],1).dot(dW2.reshape(1,dW2.shape[0]))*lr\n",
        "  new_W1 = W1 - x.reshape(x.shape[0],1).dot(dW1.reshape(1,dW1.shape[0]))*lr\n",
        "\n",
        "  W1 = new_W1\n",
        "  W2 = new_W2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:  0.2890965624643017 epoch :  1000\n",
            "loss:  0.1638788697447187 epoch :  2000\n",
            "loss:  0.12136739695691326 epoch :  3000\n",
            "loss:  0.09867560029137008 epoch :  4000\n",
            "loss:  0.08364132301318258 epoch :  5000\n",
            "loss:  0.07263169161517347 epoch :  6000\n",
            "loss:  0.06481531714338667 epoch :  7000\n",
            "loss:  0.05902942711007908 epoch :  8000\n",
            "loss:  0.05451536091624163 epoch :  9000\n",
            "loss:  0.0508562175042173 epoch :  10000\n",
            "loss:  0.047808606755305044 epoch :  11000\n",
            "loss:  0.04521925321553125 epoch :  12000\n",
            "loss:  0.042985401232232844 epoch :  13000\n",
            "loss:  0.04103476251039245 epoch :  14000\n",
            "loss:  0.03931456730885693 epoch :  15000\n",
            "loss:  0.03778516685051032 epoch :  16000\n",
            "loss:  0.03641607537845714 epoch :  17000\n",
            "loss:  0.035183402960242985 epoch :  18000\n",
            "loss:  0.034068123226470855 epoch :  19000\n",
            "loss:  0.033054864145599674 epoch :  20000\n",
            "loss:  0.03213103808596204 epoch :  21000\n",
            "loss:  0.03128619867295947 epoch :  22000\n",
            "loss:  0.030511553837866877 epoch :  23000\n",
            "loss:  0.029799590475915023 epoch :  24000\n",
            "loss:  0.02914378304417119 epoch :  25000\n",
            "loss:  0.02853836949064736 epoch :  26000\n",
            "loss:  0.02797818452123654 epoch :  27000\n",
            "loss:  0.027458543039824333 epoch :  28000\n",
            "loss:  0.026975166411101422 epoch :  29000\n",
            "loss:  0.026524142342747407 epoch :  30000\n",
            "loss:  0.02610190741349274 epoch :  31000\n",
            "loss:  0.025705241037098463 epoch :  32000\n",
            "loss:  0.025331261429272608 epoch :  33000\n",
            "loss:  0.02497741735031167 epoch :  34000\n",
            "loss:  0.024641472903604175 epoch :  35000\n",
            "loss:  0.024321485493064128 epoch :  36000\n",
            "loss:  0.024015778724482992 epoch :  37000\n",
            "loss:  0.023722912634423565 epoch :  38000\n",
            "loss:  0.023441653481334083 epoch :  39000\n",
            "loss:  0.023170944812889366 epoch :  40000\n",
            "loss:  0.022909880914704882 epoch :  41000\n",
            "loss:  0.022657683208956458 epoch :  42000\n",
            "loss:  0.02241367976915459 epoch :  43000\n",
            "loss:  0.022177287852143616 epoch :  44000\n",
            "loss:  0.021947999195991268 epoch :  45000\n",
            "loss:  0.021725367761643848 epoch :  46000\n",
            "loss:  0.021508999578816537 epoch :  47000\n",
            "loss:  0.02129854437079498 epoch :  48000\n",
            "loss:  0.02109368866346687 epoch :  49000\n",
            "loss:  0.0208941501211524 epoch :  50000\n",
            "loss:  0.020699672889816938 epoch :  51000\n",
            "loss:  0.020510023763847546 epoch :  52000\n",
            "loss:  0.020324989024260103 epoch :  53000\n",
            "loss:  0.020144371823504446 epoch :  54000\n",
            "loss:  0.019967990015065232 epoch :  55000\n",
            "loss:  0.01979567434516277 epoch :  56000\n",
            "loss:  0.01962726693956658 epoch :  57000\n",
            "loss:  0.019462620031331732 epoch :  58000\n",
            "loss:  0.019301594885653212 epoch :  59000\n",
            "loss:  0.019144060886418564 epoch :  60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZv26KaktWww"
      },
      "source": [
        "Melakukan Prediksi (feed forward)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_bfSSpG6Sr_"
      },
      "source": [
        "** melakukan prediksi untuk ke-6 data (baik 4 data yang telah ikut training maupun 2 data yang belum pernah dikenali model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzOdPPG4KL_c",
        "outputId": "04775c23-20b4-4bd4-ad6e-2439f29caacf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "pred = []\n",
        "print(\"Training Data\")\n",
        "for i in range(len(data)):\n",
        "  \n",
        "  # feed forward\n",
        "  x = input_bpnn[i]\n",
        "  t = output_bpnn[i]\n",
        "\n",
        "  h = np.dot(W1.T, x)\n",
        "  g = sigmoid(h)\n",
        "  u = np.dot(W2.T, g)\n",
        "  y =  sigmoid(u)\n",
        "\n",
        "  if i == 4: \n",
        "    print('===============')\n",
        "    print(\"Testing Data\")\n",
        "\n",
        "   # melakukan pembulatan, jika dibawah 0.5 maka 0, sebaliknya maka 1 \n",
        "  if y<0.5: pred.append(0)\n",
        "  else: pred.append(1)\n",
        "\n",
        "  print(y, t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data\n",
            "[0.96686618] 1\n",
            "[0.04260688] 0\n",
            "[0.96739793] 1\n",
            "[0.01914348] 0\n",
            "===============\n",
            "Testing Data\n",
            "[0.97185685] 0\n",
            "[0.12769301] 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR5QX2E_4QSh"
      },
      "source": [
        "Dapat dilihat bahwa hasil prediksi telah konvergen ke nilai target untuk semua train data, tetapi mengalami konvergensi yang terbalik pada test data (saat target test data adalah 1 maka hasil BPNN konvergen ke 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GEORSNlff-a"
      },
      "source": [
        "# Performance Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9IAkBkD8QCv",
        "outputId": "6a676671-b522-417d-93c6-06c691510a5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "print('Train')\n",
        "print(confusion_matrix(data['label'].head(4),pred[:4]))\n",
        "print(\"============\")\n",
        "print('Test')\n",
        "print(confusion_matrix(data['label'].tail(2),pred[4:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "[[2 0]\n",
            " [0 2]]\n",
            "============\n",
            "Test\n",
            "[[0 1]\n",
            " [1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k6H_NsNdoXy",
        "outputId": "0268f694-19b1-46ae-9f57-c9713db5f4f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "print('Train')\n",
        "print('accuracy: ', accuracy_score(data['label'].head(4),pred[:4]))\n",
        "print('precision: ', precision_recall_fscore_support(data['label'].head(4),pred[:4],average='micro')[0])\n",
        "print('recall: ', precision_recall_fscore_support(data['label'].head(4),pred[:4],average='micro')[1])\n",
        "print('f1: ', precision_recall_fscore_support(data['label'].head(4),pred[:4],average='micro')[2])\n",
        "print(\"============\")\n",
        "print('Test')\n",
        "print('accuracy: ', accuracy_score(data['label'].tail(2),pred[4:]))\n",
        "print('precision: ', precision_recall_fscore_support(data['label'].tail(2),pred[4:],average='micro')[0])\n",
        "print('recall: ', precision_recall_fscore_support(data['label'].tail(2),pred[4:],average='micro')[1])\n",
        "print('f1: ', precision_recall_fscore_support(data['label'].tail(2),pred[4:],average='micro')[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "accuracy:  1.0\n",
            "precision:  1.0\n",
            "recall:  1.0\n",
            "f1:  1.0\n",
            "============\n",
            "Test\n",
            "accuracy:  0.0\n",
            "precision:  0.0\n",
            "recall:  0.0\n",
            "f1:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMbwAlkq4Ja8"
      },
      "source": [
        "Peforma akurasi, presisi, dan recall pada training data adalah 100% sedangakan pada testing data adalah 0%. Hal ini secara umum dapat dikatakan sebagai overfitting, yang mana model sangat baik di training namun berbeda jauh dengan saat testing. Pada data kali ini, dapat dilihat bahwa banyaknya kata unik hampir sama dengan banyaknya kata secara keseluruhan (hanya kata 'movie' dan 'all' yang muncul lebih dari 1 kali) hal ini membuat model BPNN tidak memiliki kesempatan yang baik untuk melihat kelompok kata mana yang merupakan positif dan kelompok kata mana yang merupakan negatif. Banyaknya data yang hanya 6 dan hanya 4 yang digunakan untuk training juga menjadi salah satu ufaktor kurangnya kosakata (knowledge) bagi model tersebut. Adapun rumus untuk menghitung akurasi, presisi, dan recall adalah: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SiKjyWv8sLE"
      },
      "source": [
        "$$ accuracy =  \\frac{True Positive + True Negative}{Total} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xObe7V9-9JT3"
      },
      "source": [
        "$$ precision =  \\frac{True Positive}{True Positive + False Positive} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHaxAxFY9s6j"
      },
      "source": [
        "$$ recall =  \\frac{True Positive}{True Positive + False Negative} $$"
      ]
    }
  ]
}